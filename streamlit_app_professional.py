# streamlit_app_professional.py
"""
Professional AI SDLC Wizard with Multi-Language Support and Autonomous Features
"""

import os
import streamlit as st
from dotenv import load_dotenv
from langgraph.checkpoint.memory import MemorySaver
import time
from datetime import datetime
import json
import plotly.graph_objects as go
import plotly.express as px
from pathlib import Path
import pandas as pd

# Import configurations and modules
from config import Config, ActiveConfig
from autonomous_features import (
    AutonomousDecisionEngine, 
    AutonomyLevel, 
    ErrorRecoveryEngine,
    WorkflowOptimizer
)
from ui_utils import (
    WorkflowAnalytics,
    ExportManager,
    NotificationManager,
    ValidationHelper
)
from advanced_features import show_advanced_features

# Import the original graph
from sdlc_graph import graph, State

load_dotenv()
os.environ["GROQ_API_KEY"] = os.getenv("GROQ_API_KEY")

# Page Configuration
st.set_page_config(
    page_title="AI SDLC Wizard - Professional Edition",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Professional CSS with Dark Mode Support
st.markdown("""
<style>
    /* Import Google Fonts */
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&display=swap');
    
    /* Root Variables */
    :root {
        --primary-color: #667eea;
        --secondary-color: #764ba2;
        --success-color: #10b981;
        --warning-color: #f59e0b;
        --error-color: #ef4444;
        --bg-primary: #ffffff;
        --bg-secondary: #f5f7fa;
        --text-primary: #1e293b;
        --text-secondary: #64748b;
        --border-color: rgba(0, 0, 0, 0.05);
    }
    
    /* Dark Mode Variables */
    .dark-mode {
        --bg-primary: #1a1a1a;
        --bg-secondary: #2d2d2d;
        --text-primary: #ffffff;
        --text-secondary: #a0a0a0;
        --border-color: rgba(255, 255, 255, 0.1);
    }
    
    /* Global Styles */
    .main {
        font-family: 'Inter', sans-serif;
        background: var(--bg-secondary);
        color: var(--text-primary);
    }
    
    /* Code Blocks */
    pre, code {
        font-family: 'JetBrains Mono', monospace !important;
    }
    
    /* Professional Card */
    .pro-card {
        background: var(--bg-primary);
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.07);
        margin-bottom: 1rem;
        border: 1px solid var(--border-color);
        transition: all 0.3s ease;
    }
    
    .pro-card:hover {
        box-shadow: 0 8px 15px rgba(0, 0, 0, 0.1);
        transform: translateY(-2px);
    }
    
    /* Status Indicators */
    .status-indicator {
        display: inline-flex;
        align-items: center;
        gap: 8px;
        padding: 6px 12px;
        border-radius: 20px;
        font-size: 14px;
        font-weight: 500;
    }
    
    .status-success {
        background: rgba(16, 185, 129, 0.1);
        color: var(--success-color);
    }
    
    .status-warning {
        background: rgba(245, 158, 11, 0.1);
        color: var(--warning-color);
    }
    
    .status-error {
        background: rgba(239, 68, 68, 0.1);
        color: var(--error-color);
    }
    
    /* Quality Score Visualization */
    .quality-score {
        display: flex;
        align-items: center;
        gap: 12px;
        padding: 12px;
        background: var(--bg-secondary);
        border-radius: 8px;
        margin: 8px 0;
    }
    
    .quality-bar {
        flex: 1;
        height: 8px;
        background: var(--border-color);
        border-radius: 4px;
        overflow: hidden;
    }
    
    .quality-fill {
        height: 100%;
        transition: width 0.5s ease;
    }
    
    .quality-excellent { background: var(--success-color); }
    .quality-good { background: #3b82f6; }
    .quality-fair { background: var(--warning-color); }
    .quality-poor { background: var(--error-color); }
    
    /* Autonomous Mode Indicator */
    .autonomy-badge {
        display: inline-flex;
        align-items: center;
        gap: 8px;
        padding: 8px 16px;
        background: linear-gradient(135deg, #667eea20, #764ba220);
        border: 1px solid var(--primary-color);
        border-radius: 20px;
        font-weight: 600;
    }
    
    /* Language Selector */
    .language-card {
        padding: 16px;
        border: 2px solid transparent;
        border-radius: 8px;
        cursor: pointer;
        transition: all 0.3s ease;
        text-align: center;
    }
    
    .language-card:hover {
        border-color: var(--primary-color);
        transform: translateY(-2px);
    }
    
    .language-card.selected {
        background: linear-gradient(135deg, #667eea10, #764ba210);
        border-color: var(--primary-color);
    }
    
    /* Loading Animation */
    .loading-spinner {
        display: inline-block;
        width: 20px;
        height: 20px;
        border: 3px solid rgba(102, 126, 234, 0.3);
        border-radius: 50%;
        border-top-color: var(--primary-color);
        animation: spin 1s ease-in-out infinite;
    }
    
    @keyframes spin {
        to { transform: rotate(360deg); }
    }
    
    /* Auto-save Indicator */
    .auto-save {
        position: fixed;
        top: 20px;
        right: 20px;
        padding: 8px 16px;
        background: var(--bg-primary);
        border: 1px solid var(--success-color);
        border-radius: 20px;
        font-size: 14px;
        color: var(--success-color);
        opacity: 0;
        transition: opacity 0.3s ease;
        z-index: 1000;
    }
    
    .auto-save.active {
        opacity: 1;
    }
</style>
""", unsafe_allow_html=True)

# Initialize Enhanced Session State
if "initialized" not in st.session_state:
    st.session_state.initialized = True
    import uuid
    st.session_state.thread = {"configurable": {"thread_id": str(uuid.uuid4())}}
    st.session_state.state = {
        "requirements": "",
        "programming_language": "python",
        "llm_model": Config.DEFAULT_LLM_MODEL,
        "autonomy_level": "semi_auto",
        "user_stories": [],
        "user_story_status": "Approve",
        "user_story_feedback": [],
        "design_document": {},
        "design_document_review_status": "Approve",
        "design_document_review_feedback": [],
        "code": "",
        "code_review_status": "Approve",
        "code_review_feedback": [],
        "security_review_status": "Approve",
        "security_review_feedback": "",
        "test_cases": "",
        "test_cases_review_status": "Approve",
        "test_cases_review_feedback": [],
        "qa_review_status": "Approve",
        "qa_review_feedback": [],
        "deployment": "",
        "quality_metrics": {},
        "autonomous_decisions": []
    }
    st.session_state.active_node = "User Requirements"
    st.session_state.events = []
    st.session_state.start_time = None
    st.session_state.notifications = []
    st.session_state.theme = "light"
    st.session_state.export_history = []
    st.session_state.error_recovery = ErrorRecoveryEngine()
    st.session_state.workflow_optimizer = WorkflowOptimizer()
    st.session_state.auto_save_enabled = True
    st.session_state.workflow_history = []

# Auto-save functionality
def auto_save_state():
    """Auto-save current state"""
    if st.session_state.auto_save_enabled:
        save_data = {
            "timestamp": str(datetime.now()),
            "state": st.session_state.state,
            "language": st.session_state.state.get("programming_language", "python"),
            "model": st.session_state.state.get("llm_model", Config.DEFAULT_LLM_MODEL),
            "autonomy": st.session_state.state.get("autonomy_level", "semi_auto")
        }
        
        # Save to file (in production, use database)
        os.makedirs("auto_saves", exist_ok=True)
        filename = f"auto_saves/save_{st.session_state.thread['configurable']['thread_id']}.json"
        with open(filename, "w") as f:
            json.dump(save_data, f, indent=2)

# Helper Functions
def get_quality_class(score: float) -> str:
    """Get CSS class based on quality score"""
    if score >= 0.9:
        return "quality-excellent"
    elif score >= 0.75:
        return "quality-good"
    elif score >= 0.6:
        return "quality-fair"
    else:
        return "quality-poor"

def render_quality_score(label: str, score: float):
    """Render a quality score bar"""
    quality_class = get_quality_class(score)
    percentage = int(score * 100)
    
    st.markdown(f"""
    <div class="quality-score">
        <span style="min-width: 150px;">{label}</span>
        <div class="quality-bar">
            <div class="quality-fill {quality_class}" style="width: {percentage}%"></div>
        </div>
        <span style="min-width: 50px; text-align: right;">{percentage}%</span>
    </div>
    """, unsafe_allow_html=True)

def get_completion_percentage():
    """Calculate workflow completion percentage"""
    flow_order = [
        "User Requirements", "Auto-generate User Stories", "Human User Story Approval",
        "Create Design Document", "Human Design Document Review", "Generate Code",
        "Human Code Review", "Security Review", "Human Security Review",
        "Write Test Cases", "Human Test Cases Review", "QA Testing",
        "Human QA Review", "Deployment"
    ]
    current = st.session_state.active_node
    if current in flow_order:
        return int((flow_order.index(current) + 1) / len(flow_order) * 100)
    return 0

# Sidebar Configuration
with st.sidebar:
    st.markdown("### üéõÔ∏è Professional Control Panel")
    
    # Autonomy Level Selection
    st.markdown("#### ü§ñ Autonomy Level")
    autonomy_level = st.selectbox(
        "Select automation level:",
        options=list(Config.AUTONOMY_LEVELS.keys()),
        format_func=lambda x: f"{Config.AUTONOMY_LEVELS[x]['icon']} {Config.AUTONOMY_LEVELS[x]['name']}",
        help="\n".join([f"{v['name']}: {v['description']}" for v in Config.AUTONOMY_LEVELS.values()])
    )
    st.session_state.state["autonomy_level"] = autonomy_level
    
    # LLM Model Selection
    st.markdown("#### üß† AI Model")
    selected_model = st.selectbox(
        "Select LLM model:",
        options=list(Config.AVAILABLE_MODELS.keys()),
        format_func=lambda x: Config.AVAILABLE_MODELS[x]['name'],
        help="Choose the AI model for code generation"
    )
    st.session_state.state["llm_model"] = selected_model
    
    # Model details
    model_info = Config.AVAILABLE_MODELS[selected_model]
    st.caption(f"üìù {model_info['description']}")
    st.caption(f"üìä Max tokens: {model_info['max_tokens']:,}")
    
    # Programming Language Selection
    st.markdown("#### üíª Programming Language")
    language_cols = st.columns(2)
    
    # Create language grid
    languages = list(Config.SUPPORTED_LANGUAGES.keys())
    selected_language = st.session_state.state.get("programming_language", "python")
    
    for i, lang in enumerate(languages):
        col = language_cols[i % 2]
        with col:
            if st.button(
                Config.SUPPORTED_LANGUAGES[lang]['name'],
                key=f"lang_{lang}",
                use_container_width=True,
                type="primary" if lang == selected_language else "secondary"
            ):
                st.session_state.state["programming_language"] = lang
                st.rerun()
    
    # Workflow Statistics
    st.markdown("#### üìä Workflow Statistics")
    stats_container = st.container()
    with stats_container:
        # Decision statistics
        autonomous_decisions = st.session_state.state.get("autonomous_decisions", [])
        total_decisions = len(autonomous_decisions)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Auto Decisions", total_decisions)
        with col2:
            avg_score = sum(d.get('score', 0) for d in autonomous_decisions) / max(1, total_decisions)
            st.metric("Avg Quality", f"{avg_score:.2f}")
    
    # Advanced Settings
    with st.expander("‚öôÔ∏è Advanced Settings", expanded=False):
        st.session_state.auto_save_enabled = st.checkbox("Enable Auto-Save", value=True)
        show_metrics = st.checkbox("Show Quality Metrics", value=True)
        error_recovery = st.checkbox("Enable Error Recovery", value=True)
        quality_threshold = st.slider("Quality Threshold", 0.0, 1.0, 0.8, 0.05)
        
        # Export Settings
        st.markdown("##### üì• Export Options")
        export_format = st.multiselect(
            "Export formats:",
            ["PDF", "Word", "JSON", "ZIP"],
            default=["PDF", "ZIP"]
        )
    
    # Quick Actions
    st.markdown("### ‚ö° Quick Actions")
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("üíæ Save Project", use_container_width=True):
            auto_save_state()
            st.success("Project saved!")
    
    with col2:
        if st.button("üìä Analytics", use_container_width=True):
            st.session_state.show_analytics = True
    
    if st.button("üöÄ Export All", use_container_width=True, type="primary"):
        with st.spinner("Exporting artifacts..."):
            export_manager = ExportManager()
            zip_file = export_manager.export_all_artifacts(st.session_state.state)
            st.success(f"Exported to {zip_file}")

# Main Header with Professional Styling
st.markdown(f"""
<div class="pro-card" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; text-align: center;">
    <h1 style="margin: 0; font-size: 2.5rem;">üöÄ AI SDLC Wizard - Professional Edition</h1>
    <p style="margin: 10px 0 20px 0; opacity: 0.9;">
        Multi-Language ‚Ä¢ Autonomous ‚Ä¢ Enterprise-Ready
    </p>
    <div style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
        <div class="status-indicator" style="background: rgba(255,255,255,0.2); color: white;">
            üíª {Config.SUPPORTED_LANGUAGES[st.session_state.state.get('programming_language', 'python')]['name']}
        </div>
        <div class="status-indicator" style="background: rgba(255,255,255,0.2); color: white;">
            üß† {Config.AVAILABLE_MODELS[st.session_state.state.get('llm_model', Config.DEFAULT_LLM_MODEL)]['name']}
        </div>
        <div class="status-indicator" style="background: rgba(255,255,255,0.2); color: white;">
            {Config.AUTONOMY_LEVELS[st.session_state.state.get('autonomy_level', 'manual')]['icon']} 
            {Config.AUTONOMY_LEVELS[st.session_state.state.get('autonomy_level', 'manual')]['name']}
        </div>
    </div>
</div>
""", unsafe_allow_html=True)

# Enhanced Progress Tracker
def render_enhanced_progress():
    """Render enhanced progress tracker with quality indicators"""
    st.markdown("### üéØ Intelligent Workflow Progress")
    
    # Progress bar
    progress = get_completion_percentage()
    st.progress(progress / 100)
    st.caption(f"Progress: {progress}% Complete")
    
    # Stage indicators
    flow_order = [
        ("User Requirements", "üìã"),
        ("Auto-generate User Stories", "ü§ñ"),
        ("Human User Story Approval", "üë•"),
        ("Create Design Document", "üìê"),
        ("Human Design Document Review", "üîç"),
        ("Generate Code", "üíª"),
        ("Human Code Review", "üë®‚Äçüíª"),
        ("Security Review", "üîí"),
        ("Human Security Review", "üõ°Ô∏è"),
        ("Write Test Cases", "üß™"),
        ("Human Test Cases Review", "‚úîÔ∏è"),
        ("QA Testing", "üéØ"),
        ("Human QA Review", "‚úÖ"),
        ("Deployment", "üöÄ")
    ]
    
    cols = st.columns(7)
    for i, (stage, icon) in enumerate(flow_order):
        col = cols[i % 7]
        with col:
            # Check if this stage had autonomous decision
            auto_decision = any(
                d.get('stage', '').replace(' ', '_').lower() in stage.replace(' ', '_').lower() 
                for d in st.session_state.state.get('autonomous_decisions', [])
            )
            
            if auto_decision:
                st.markdown(f"""
                <div style="text-align: center;">
                    <div style="font-size: 24px;">{icon}</div>
                    <div style="font-size: 10px; color: var(--primary-color);">‚úì AUTO</div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="text-align: center; opacity: 0.6;">
                    <div style="font-size: 24px;">{icon}</div>
                    <div style="font-size: 10px;">&nbsp;</div>
                </div>
                """, unsafe_allow_html=True)

render_enhanced_progress()

# Quality Metrics Dashboard
if st.session_state.state.get("quality_metrics"):
    st.markdown("### üìä Quality Metrics")
    metrics = st.session_state.state.get("quality_metrics", {})
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        render_quality_score("Completeness", metrics.get("completeness_score", 0))
    with col2:
        render_quality_score("Consistency", metrics.get("consistency_score", 0))
    with col3:
        render_quality_score("Security", metrics.get("security_score", 0))
    with col4:
        render_quality_score("Best Practices", metrics.get("best_practices_score", 0))

# Main Content Tabs
tabs = st.tabs([
    "üìã Requirements",
    "üìò User Stories",
    "üìê Design",
    "üíª Code",
    "üß™ Tests",
    "üîí Security",
    "‚úÖ QA",
    "üöÄ Deploy",
    "üìä Analytics",
    "ü§ñ AI Insights"
])

state = st.session_state.state

# Tab 1: Requirements
with tabs[0]:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üìù Project Requirements")
        
        # Language-specific placeholder
        lang_config = Config.SUPPORTED_LANGUAGES.get(state.get("programming_language", "python"), {})
        placeholder = f"""Describe your {lang_config.get('name', 'software')} project in detail...

Example for {lang_config.get('name', 'software')}:
Create a {lang_config.get('name', 'software').lower()} application that:
- Implements user authentication
- Provides RESTful API endpoints
- Includes data validation
- Has comprehensive error handling
- Follows {lang_config.get('name', 'software')} best practices"""
        
        # Requirements input
        default_requirements = state.get("requirements", "")
        if "template_to_use" in st.session_state:
            default_requirements = st.session_state.template_to_use
            state['requirements'] = st.session_state.template_to_use
            st.session_state.state = state
            del st.session_state.template_to_use
        
        requirements = st.text_area(
            "Enter your project requirements:",
            default_requirements,
            height=300,
            placeholder=placeholder,
            key="requirements_input"
        )
        
        # Update state
        state['requirements'] = requirements
        st.session_state.state = state
        
        # Validation
        word_count = len(requirements.split()) if requirements else 0
        errors, warnings = ValidationHelper.validate_requirements(requirements)
        
        # Display validation results
        if errors:
            for error in errors:
                st.error(f"‚ùå {error}")
        
        if warnings and word_count > 0:
            with st.expander("üí° Suggestions for better results"):
                for warning in warnings:
                    st.info(f"üí° {warning}")
        
        st.caption(f"üìä Word count: {word_count} | Recommended: 50-500 words")
        
        # Start Workflow Button
        if st.button("üöÄ Start Intelligent Workflow", type="primary", use_container_width=True):
            current_requirements = st.session_state.requirements_input
            word_count = len(current_requirements.split()) if current_requirements else 0
            
            if word_count < 10:
                st.error("‚ùå Please provide more detailed requirements (at least 10 words)")
            else:
                try:
                    # Start timer
                    st.session_state.start_time = datetime.now()
                    
                    # Update state
                    state['requirements'] = current_requirements
                    st.session_state.state = state
                    
                    # Auto-save
                    auto_save_state()
                    
                    # Progress animation
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    # Start the graph stream
                    for i, event in enumerate(graph.stream(state, st.session_state.thread)):
                        st.session_state.events.append(event)
                        for node, output in event.items():
                            if isinstance(output, dict):
                                st.session_state.state.update(output)
                            st.session_state.active_node = node
                            
                            # Update progress
                            progress_bar.progress(min((i + 1) * 10, 100))
                            status_text.text(f"üîÑ Processing: {node}...")
                            
                            time.sleep(0.1)
                    
                    st.success("‚úÖ Workflow started successfully!")
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"‚ùå Error: {str(e)}")
                    if hasattr(st.session_state, 'error_recovery'):
                        st.info("üîß Error recovery system activated")
    
    with col2:
        st.markdown("### üí° AI-Powered Suggestions")
        
        # Language-specific tips
        lang_tips = {
            "python": [
                "Mention if you need async/await support",
                "Specify Python version (3.8+)",
                "Include required libraries",
                "Mention if type hints are needed"
            ],
            "javascript": [
                "Specify Node.js or browser environment",
                "Mention framework preferences (React, Vue, etc.)",
                "Include ES6+ feature requirements",
                "Specify build tool preferences"
            ],
            "java": [
                "Specify Java version (8, 11, 17)",
                "Mention Spring Boot if needed",
                "Include build tool (Maven/Gradle)",
                "Specify enterprise features"
            ],
            "go": [
                "Mention Go version (1.18+)",
                "Specify if you need concurrency",
                "Include package dependencies",
                "Mention deployment target"
            ],
            "csharp": [
                "Specify .NET version",
                "Mention if you need ASP.NET",
                "Include NuGet packages",
                "Specify deployment environment"
            ]
        }
        
        current_lang = state.get("programming_language", "python")
        tips = lang_tips.get(current_lang, ["Be specific about requirements"])
        
        st.info(f"**{Config.SUPPORTED_LANGUAGES[current_lang]['name']} Tips:**\n" + 
                "\n".join([f"‚Ä¢ {tip}" for tip in tips]))
        
        # Enhanced Templates
        with st.expander("üìÑ Professional Templates"):
            template = st.selectbox(
                "Choose a template:",
                list(Config.REQUIREMENT_TEMPLATES.keys())
            )
            
            template_info = Config.REQUIREMENT_TEMPLATES[template]
            st.caption(f"üìù {template_info['description']}")
            
            if st.button("Use This Template", use_container_width=True):
                st.session_state.template_to_use = template_info['template']
                st.rerun()

# Tab 2: User Stories (with Autonomous Features)
with tabs[1]:
    st.markdown("### üìö Generated User Stories")
    
    user_stories = st.session_state.state.get("user_stories", [])
    
    if user_stories:
        # Quality Analysis (if autonomous features are available)
        if state.get("autonomy_level") != "manual":
            try:
                auto_engine = AutonomousDecisionEngine(AutonomyLevel(state.get("autonomy_level", "semi_auto")))
                decision, metrics, feedback = auto_engine.analyze_user_stories(
                    user_stories,
                    state.get("requirements", "")
                )
                
                # Display quality metrics
                col1, col2, col3 = st.columns([2, 1, 1])
                
                with col1:
                    st.markdown("#### üìä Quality Analysis")
                    render_quality_score("Story Completeness", metrics.completeness_score)
                    render_quality_score("Requirements Alignment", metrics.consistency_score)
                    render_quality_score("Best Practices", metrics.best_practices_score)
                    render_quality_score("Overall Quality", metrics.overall_score)
                
                with col2:
                    st.markdown("#### ü§ñ AI Recommendation")
                    if decision == "Approve":
                        st.success(f"‚úÖ {decision}")
                    else:
                        st.warning(f"‚ö†Ô∏è {decision}")
                    st.caption(feedback)
                
                with col3:
                    st.markdown("#### üìà Metrics")
                    st.metric("Stories", len(user_stories))
                    st.metric("Quality", f"{int(metrics.overall_score * 100)}%")
                    st.metric("Autonomy", state.get("autonomy_level", "manual").title())
            except Exception as e:
                st.warning(f"Quality analysis unavailable: {str(e)}")
        
        # Display stories
        for i, story in enumerate(user_stories, 1):
            st.markdown(f"""
            <div class="pro-card">
                <h4 style="color: var(--primary-color); margin-bottom: 10px;">Story #{i}</h4>
                <p style="margin: 0;">{story}</p>
            </div>
            """, unsafe_allow_html=True)
        
        # Review Section
        st.markdown("### üîç Review User Stories")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            status = st.radio(
                "Do these user stories meet your requirements?",
                ["Approve", "Denied"],
                horizontal=True,
                key="user_stories_approval"
            )
            
            if status == "Denied":
                feedback_text = st.text_area(
                    "Please provide specific feedback:",
                    placeholder="E.g., Missing admin functionality, need more detail on payment processing...",
                    key="user_stories_feedback"
                )
        
        with col2:
            st.markdown("### üìã Review Checklist")
            checks = [
                st.checkbox("Stories follow format", value=True),
                st.checkbox("All features covered", value=True),
                st.checkbox("Testable criteria", value=True),
                st.checkbox("User-focused", value=True)
            ]
        
        if st.button("‚úÖ Submit Review", type="primary", use_container_width=True):
            feedback_text = st.session_state.get("user_stories_feedback", "") if status == "Denied" else ""
            graph.update_state(
                st.session_state.thread,
                {"user_story_status": status, "user_story_feedback": [feedback_text]},
                as_node="Human User Story Approval"
            )
            
            with st.spinner("Processing your feedback..."):
                for event in graph.stream(None, st.session_state.thread):
                    st.session_state.events.append(event)
                    for node, output in event.items():
                        if isinstance(output, dict):
                            st.session_state.state.update(output)
                        st.session_state.active_node = node
            
            st.success(f"‚úÖ User stories {status.lower()}!")
            auto_save_state()
            st.rerun()
    else:
        st.info("ü§ñ User stories will be generated after you submit requirements.")

# Tab 3: Design Document
with tabs[2]:
    st.markdown("### üìê Technical Design Document")
    
    doc = st.session_state.state.get("design_document", {})
    has_content = any(doc.get(section, []) for section in ["functional", "technical", "assumptions", "open_questions"])
    
    if has_content:
        # Design Document Viewer
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # Functional Requirements
            if doc.get("functional"):
                with st.expander("üéØ Functional Requirements", expanded=True):
                    for item in doc["functional"]:
                        st.markdown(f"‚Ä¢ {item}")
            
            # Technical Requirements
            if doc.get("technical"):
                with st.expander("‚öôÔ∏è Technical Requirements", expanded=True):
                    for item in doc["technical"]:
                        st.markdown(f"‚Ä¢ {item}")
            
            # Assumptions
            if doc.get("assumptions"):
                with st.expander("üí≠ Assumptions", expanded=False):
                    for item in doc["assumptions"]:
                        st.markdown(f"‚Ä¢ {item}")
            
            # Open Questions
            if doc.get("open_questions"):
                with st.expander("‚ùì Open Questions / Risks", expanded=False):
                    for item in doc["open_questions"]:
                        st.markdown(f"‚Ä¢ {item}")
        
        with col2:
            st.markdown("### üìÑ Document Actions")
            if st.button("üì• Export to Word", use_container_width=True):
                st.success("‚úÖ Document exported to artifacts/design_document.docx")
        
        # Review Section
        st.markdown("### üîç Review Design Document")
        status = st.radio(
            "Is the design document complete and accurate?",
            ["Approve", "Denied"],
            horizontal=True,
            key="design_doc_approval"
        )
        
        if status == "Denied":
            feedback = st.text_area(
                "What needs to be improved?",
                placeholder="E.g., Need more detail on API endpoints, missing database schema...",
                key="design_doc_feedback"
            )
        
        if st.button("‚úÖ Submit Design Review", type="primary", use_container_width=True):
            feedback_text = st.session_state.get("design_doc_feedback", "") if status == "Denied" else ""
            graph.update_state(
                st.session_state.thread,
                {"design_document_review_status": status, "design_document_review_feedback": [feedback_text]},
                as_node="Human Design Document Review"
            )
            
            with st.spinner("Processing design review..."):
                for event in graph.stream(None, st.session_state.thread):
                    st.session_state.events.append(event)
                    for node, output in event.items():
                        if isinstance(output, dict):
                            st.session_state.state.update(output)
                        st.session_state.active_node = node
            
            st.success(f"Design document {status.lower()}!")
            st.rerun()
    else:
        st.info("üìê Design document will be created after user stories are approved.")

# Tab 4: Code Generation
with tabs[3]:
    st.markdown("### üíª Generated Source Code")
    
    code = st.session_state.state.get("code", "")
    
    if code and code != "No code generated yet.":
        # Language-specific display
        lang = state.get("programming_language", "python")
        lang_config = Config.SUPPORTED_LANGUAGES[lang]
        st.markdown(f"#### Generated {lang_config['name']} Code")
        
        # Code quality analysis (if autonomous features are available)
        if state.get("autonomy_level") != "manual":
            try:
                auto_engine = AutonomousDecisionEngine(AutonomyLevel(state.get("autonomy_level", "semi_auto")))
                decision, metrics, feedback = auto_engine.analyze_code(
                    code,
                    state.get("design_document", {}),
                    lang
                )
                
                # Display metrics
                col1, col2 = st.columns([3, 1])
                with col1:
                    render_quality_score("Code Structure", metrics.completeness_score)
                    render_quality_score("Security", metrics.security_score)
                    render_quality_score("Best Practices", metrics.best_practices_score)
                with col2:
                    st.markdown("#### ü§ñ AI Analysis")
                    if decision == "Approve":
                        st.success(f"‚úÖ {decision}")
                    else:
                        st.warning(f"‚ö†Ô∏è {decision}")
                    st.caption(feedback[:100] + "..." if len(feedback) > 100 else feedback)
            except Exception as e:
                st.warning(f"Code analysis unavailable: {str(e)}")
        
        # Code Statistics
        col1, col2, col3, col4 = st.columns(4)
        lines_of_code = len(code.split('\n'))
        
        with col1:
            st.metric("Lines of Code", f"{lines_of_code:,}")
        with col2:
            files_count = code.count("Filename:")
            st.metric("Files Generated", files_count)
        with col3:
            st.metric("Language", lang_config['name'])
        with col4:
            st.metric("Status", "Ready for Review")
        
        # Display code files
        if os.path.exists("generated_code"):
            files = os.listdir("generated_code")
            if files:
                st.markdown("#### üìÑ Source Files")
                selected_file = st.selectbox("Select a file to view:", files)
                
                if selected_file:
                    file_path = os.path.join("generated_code", selected_file)
                    with open(file_path, 'r') as f:
                        file_content = f.read()
                    
                    st.code(file_content, language=lang.lower(), line_numbers=True)
        else:
            st.code(code, language=lang.lower())
        
        # Code Review Section
        st.markdown("### üîç Code Review")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            status = st.radio(
                "Does the code meet your quality standards?",
                ["Approve", "Denied"],
                horizontal=True,
                key="code_approval"
            )
            
            if status == "Denied":
                feedback = st.text_area(
                    "Describe the issues found:",
                    placeholder="E.g., Missing error handling, need better documentation, security concerns...",
                    height=150,
                    key="code_feedback"
                )
        
        with col2:
            st.markdown("#### üìã Review Checklist")
            st.checkbox("‚úÖ Follows coding standards")
            st.checkbox("‚úÖ Proper error handling")
            st.checkbox("‚úÖ Well documented")
            st.checkbox("‚úÖ Modular design")
            st.checkbox("‚úÖ Security best practices")
        
        if st.button("‚úÖ Submit Code Review", type="primary", use_container_width=True):
            feedback_text = st.session_state.get("code_feedback", "") if status == "Denied" else ""
            graph.update_state(
                st.session_state.thread,
                {"code_review_status": status, "code_review_feedback": [feedback_text]},
                as_node="Human Code Review"
            )
            
            with st.spinner("Processing code review..."):
                for event in graph.stream(None, st.session_state.thread):
                    st.session_state.events.append(event)
                    for node, output in event.items():
                        if isinstance(output, dict):
                            st.session_state.state.update(output)
                        st.session_state.active_node = node
            
            st.success(f"Code {status.lower()}!")
            st.rerun()
    else:
        st.info("üíª Code will be generated after the design document is approved.")

# Tab 5: Test Cases
with tabs[4]:
    st.markdown("### üß™ Test Cases")
    
    test_cases = st.session_state.state.get("test_cases", "")
    
    if test_cases and test_cases != "No test cases yet.":
        # Test Statistics
        col1, col2, col3 = st.columns(3)
        test_count = test_cases.count("[Test Case Name]:")
        
        with col1:
            st.metric("Total Test Cases", test_count)
        with col2:
            st.metric("Test Types", "Unit, Integration, E2E")
        with col3:
            st.metric("Coverage", "Comprehensive")
        
        # Display test cases
        test_case_blocks = test_cases.split("---")
        
        for i, test_block in enumerate(test_case_blocks):
            if test_block.strip():
                # Extract test name
                name_match = test_block.find("[Test Case Name]:")
                if name_match != -1:
                    name_end = test_block.find("\n", name_match)
                    test_name = test_block[name_match + 16:name_end].strip()
                    
                    with st.expander(f"üß™ {test_name}", expanded=i < 3):
                        st.text(test_block.strip())
        
        # Test Review Section
        st.markdown("### üîç Test Case Review")
        
        status = st.radio(
            "Are the test cases comprehensive and appropriate?",
            ["Approve", "Denied"],
            horizontal=True,
            key="test_cases_approval"
        )
        
        if status == "Denied":
            feedback = st.text_area(
                "What test scenarios are missing or need improvement?",
                placeholder="E.g., Missing edge cases, need performance tests, add security tests...",
                key="test_cases_feedback"
            )
        
        if st.button("‚úÖ Submit Test Review", type="primary", use_container_width=True):
            feedback_text = st.session_state.get("test_cases_feedback", "") if status == "Denied" else ""
            graph.update_state(
                st.session_state.thread,
                {"test_cases_review_status": status, "test_cases_review_feedback": [feedback_text]},
                as_node="Human Test Cases Review"
            )
            
            with st.spinner("Processing test case review..."):
                for event in graph.stream(None, st.session_state.thread):
                    st.session_state.events.append(event)
                    for node, output in event.items():
                        if isinstance(output, dict):
                            st.session_state.state.update(output)
                        st.session_state.active_node = node
            
            st.success(f"Test cases {status.lower()}!")
            st.rerun()
    else:
        st.info("üß™ Test cases will be generated after security review is complete.")

# Tab 6: Security Review
with tabs[5]:
    st.markdown("### üîí Security Assessment")
    
    security_feedback = st.session_state.state.get("security_review_feedback", "")
    
    if security_feedback and security_feedback != "N/A":
        # Security Display
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("#### üõ°Ô∏è Security Analysis Results")
            
            security_status = st.session_state.state.get("security_review_status", "")
            
            if security_status == "Approve":
                st.success("‚úÖ **Security Status: PASSED**")
            else:
                st.error("‚ùå **Security Status: NEEDS ATTENTION**")
            
            st.markdown(f"""
            <div class="pro-card">
                {security_feedback}
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            # Security metrics visualization
            st.markdown("#### üìä Security Metrics")
            
            fig = go.Figure(go.Indicator(
                mode = "gauge+number",
                value = 85 if security_status == "Approve" else 45,
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "Security Score"},
                gauge = {
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "darkgreen" if security_status == "Approve" else "darkred"},
                    'steps': [
                        {'range': [0, 50], 'color': "lightgray"},
                        {'range': [50, 80], 'color': "yellow"},
                        {'range': [80, 100], 'color': "lightgreen"}
                    ]
                }
            ))
            fig.update_layout(height=200, margin=dict(l=20, r=20, t=40, b=20))
            st.plotly_chart(fig, use_container_width=True)
        
        # Manual Security Review
        st.markdown("### üîç Manual Security Review")
        
        status = st.radio(
            "Do you approve the security assessment?",
            ["Approve", "Denied"],
            horizontal=True,
            key="security_approval"
        )
        
        if status == "Denied":
            security_feedback_text = st.text_area(
                "Additional security concerns:",
                placeholder="E.g., Need encryption for sensitive data, implement rate limiting...",
                key="security_feedback"
            )
        
        if st.button("‚úÖ Submit Security Review", type="primary", use_container_width=True):
            feedback_text = st.session_state.get("security_feedback", "") if status == "Denied" else ""
            graph.update_state(
                st.session_state.thread,
                {"security_review_status": status, "security_review_feedback": feedback_text},
                as_node="Human Security Review"
            )
            
            with st.spinner("Processing security review..."):
                for event in graph.stream(None, st.session_state.thread):
                    st.session_state.events.append(event)
                    for node, output in event.items():
                        if isinstance(output, dict):
                            st.session_state.state.update(output)
                        st.session_state.active_node = node
            
            st.success(f"Security review {status.lower()}!")
            st.rerun()
    else:
        st.info("üîí Security review will be performed after code review is complete.")

# Tab 7: QA Testing
with tabs[6]:
    st.markdown("### ‚úÖ Quality Assurance")
    
    qa_feedback = st.session_state.state.get("qa_review_feedback", [])
    qa_status = st.session_state.state.get("qa_review_status", "")
    
    if qa_feedback:
        # QA Dashboard
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.markdown("#### üéØ QA Test Results")
            
            if qa_status == "Approve":
                st.success("‚úÖ **All Tests Passed!**")
            else:
                st.warning("‚ö†Ô∏è **Issues Found During Testing**")
            
            feedback_text = "\n".join(qa_feedback) if isinstance(qa_feedback, list) else qa_feedback
            st.markdown(f"""
            <div class="pro-card">
                <h5>Test Execution Summary:</h5>
                <p>{feedback_text}</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            # Test Results Chart
            test_data = {
                "Passed": 8 if qa_status == "Approve" else 5,
                "Failed": 0 if qa_status == "Approve" else 3,
                "Skipped": 1
            }
            
            fig = px.pie(
                values=list(test_data.values()),
                names=list(test_data.keys()),
                color_discrete_map={
                    "Passed": "#10b981",
                    "Failed": "#ef4444",
                    "Skipped": "#f59e0b"
                }
            )
            fig.update_layout(height=250, showlegend=True)
            st.plotly_chart(fig, use_container_width=True)
        
        with col3:
            st.markdown("#### üìä QA Metrics")
            st.metric("Test Coverage", "92%")
            st.metric("Code Quality", "A")
            st.metric("Performance", "Good")
        
        # Manual QA Review
        st.markdown("### üîç Final QA Approval")
        
        status = st.radio(
            "Approve for deployment?",
            ["Approve", "Denied"],
            horizontal=True,
            key="qa_approval"
        )
        
        if status == "Denied":
            feedback = st.text_area(
                "What needs to be fixed before deployment?",
                placeholder="E.g., Performance issues, failing edge cases, UI bugs...",
                key="qa_feedback"
            )
        
        if st.button("‚úÖ Submit QA Decision", type="primary", use_container_width=True):
            feedback_text = st.session_state.get("qa_feedback", "") if status == "Denied" else ""
            graph.update_state(
                st.session_state.thread,
                {"qa_review_status": status, "qa_review_feedback": [feedback_text]},
                as_node="Human QA Review"
            )
            
            with st.spinner("Processing QA decision..."):
                for event in graph.stream(None, st.session_state.thread):
                    st.session_state.events.append(event)
                    for node, output in event.items():
                        if isinstance(output, dict):
                            st.session_state.state.update(output)
                        st.session_state.active_node = node
            
            st.success(f"QA {status.lower()}!")
            st.rerun()
    else:
        st.info("‚úÖ QA testing will begin after test cases are approved.")

# Tab 8: Deployment
with tabs[7]:
    st.markdown("### üöÄ Deployment Status")
    
    if state.get("deployment") == "deployed":
        # Success celebration
        st.balloons()
        
        st.markdown("""
        <div class="pro-card" style="background: linear-gradient(135deg, #d1fae5 0%, #a7f3d0 100%); border: 2px solid #10b981;">
            <h2 style="color: #065f46; text-align: center;">üéâ Deployment Successful!</h2>
            <p style="text-align: center; color: #047857; font-size: 18px;">
                Your application has been successfully deployed to production.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Deployment Details
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üìã Deployment Summary")
            deployment_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            st.markdown(f"""
            - **Environment:** Production
            - **Language:** {Config.SUPPORTED_LANGUAGES[state.get('programming_language', 'python')]['name']}
            - **Version:** 1.0.0
            - **Deployed At:** {deployment_time}
            - **Status:** Active ‚úÖ
            - **Health Check:** Passing
            """)
        
        with col2:
            st.markdown("#### üì¶ Deployment Artifacts")
            
            artifacts = {
                "User Stories": "artifacts/user_stories.txt",
                "Design Document": "artifacts/design_document.docx",
                "Source Code": "generated_code/",
                "Test Cases": "test_cases/"
            }
            
            for name, path in artifacts.items():
                if os.path.exists(path):
                    st.success(f"‚úÖ {name}")
                else:
                    st.info(f"üìÑ {name}")
    else:
        st.warning("‚è≥ **Deployment Pending**")
        st.info("Complete all review stages to enable deployment.")

# Tab 9: Analytics
with tabs[8]:
    st.markdown("### üìä Comprehensive Analytics Dashboard")
    
    if st.session_state.events:
        # Basic analytics
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Total Events", len(st.session_state.events))
        with col2:
            denials = len([e for e in st.session_state.events if "Denied" in str(e)])
            st.metric("Iterations", denials)
        with col3:
            autonomous_count = len(st.session_state.state.get("autonomous_decisions", []))
            st.metric("Auto Decisions", autonomous_count)
        
        # Timeline visualization
        if st.session_state.start_time:
            timeline_data = []
            current_time = st.session_state.start_time
            
            for i, event in enumerate(st.session_state.events):
                for node_name in event:
                    timeline_data.append({
                        'Stage': node_name,
                        'Time': current_time + pd.Timedelta(minutes=i*5),
                        'Duration': 5 + (i % 3)  # Mock duration
                    })
            
            if timeline_data:
                df = pd.DataFrame(timeline_data)
                fig = px.bar(df, x='Duration', y='Stage', orientation='h',
                           title='Stage Duration Analysis')
                st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("Analytics will be available once the workflow starts.")

# Tab 10: AI Insights
with tabs[9]:
    st.markdown("### ü§ñ AI-Powered Insights & Recommendations")
    
    try:
        # Show advanced features if available
        show_advanced_features(tabs[9], state)
    except Exception as e:
        st.warning(f"Advanced features temporarily unavailable: {str(e)}")
        
        # Fallback simple insights
        st.markdown("#### üß† Basic AI Insights")
        
        if state.get("requirements"):
            word_count = len(state["requirements"].split())
            
            if word_count < 50:
                st.info("üí° Consider adding more detail to your requirements for better AI generation")
            elif word_count > 500:
                st.warning("üí° Your requirements are quite detailed. Consider breaking into phases.")
            else:
                st.success("üí° Your requirements are well-sized for optimal AI processing")
        
        # Language-specific insights
        lang = state.get("programming_language", "python")
        lang_config = Config.SUPPORTED_LANGUAGES[lang]
        
        st.markdown(f"#### üíª {lang_config['name']} Recommendations")
        st.info(f"""
        **Framework:** {lang_config['test_framework']} for testing
        **Package Manager:** {lang_config['package_manager']}
        **Best Practices:** Follow {lang_config['name']} coding standards
        """)

# Footer with Professional Branding
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: var(--text-secondary); padding: 20px;">
    <p>üöÄ AI SDLC Wizard Professional Edition | Multi-Language | Autonomous | Enterprise-Ready</p>
    <p style="font-size: 12px;">Powered by Advanced AI | Built with LangGraph & Streamlit | v3.0 Professional</p>
</div>
""", unsafe_allow_html=True)

# Auto-refresh for real-time updates (only in autonomous modes)
if (st.session_state.active_node != "Deployment" and 
    st.session_state.start_time and 
    state.get("autonomy_level") in ["full_auto", "expert_auto"]):
    
    # Auto-save every 30 seconds
    if hasattr(st.session_state, 'auto_save_enabled') and st.session_state.auto_save_enabled:
        auto_save_state()
    
    time.sleep(1)
    st.rerun()

# Error boundary
if (hasattr(st.session_state, 'error_recovery') and 
    st.session_state.error_recovery.error_history):
    with st.expander("üîß Error Recovery Log"):
        for error in st.session_state.error_recovery.error_history[-5:]:
            st.markdown(f"""
            <div class="pro-card" style="border-left: 4px solid var(--error-color);">
                <strong>Error Type:</strong> {error['type']}<br>
                <strong>Time:</strong> {error['timestamp']}<br>
                <strong>Details:</strong> {error['details']}
            </div>
            """, unsafe_allow_html=True)